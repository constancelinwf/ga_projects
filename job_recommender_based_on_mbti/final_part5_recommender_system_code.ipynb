{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 4B - Social Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <b> Notebook 5: Using our chosen model to predict MBTI for Linkedin dataset\n",
    "\n",
    "Structure of this notebook </b>\n",
    "\n",
    "* Part 1: Importing the .pkl files for chosen model & vectorizer\n",
    "* Part 2: Generating predictions/ MBTI Labels for LinkedIn dataset\n",
    "* Part 3: Generating Recommender Systems: Profile-Based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Importing .pkl files for chosen models & vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>post</th>\n",
       "      <th>processed_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tea</td>\n",
       "      <td>collaborating with colleagues to develop inter...</td>\n",
       "      <td>collaborating with colleagues to develop inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tea</td>\n",
       "      <td>i'm committed to adapting teaching styles to a...</td>\n",
       "      <td>i'm committed to adapting teaching styles to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tea</td>\n",
       "      <td>my goal is to prepare students for success in ...</td>\n",
       "      <td>my goal is to prepare students for success in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tea</td>\n",
       "      <td>i am dedicated to preparing students for succe...</td>\n",
       "      <td>i am dedicated to preparing students for succe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tea</td>\n",
       "      <td>living life by default versus living life by d...</td>\n",
       "      <td>living life by default versus living life by d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_title                                               post  \\\n",
       "0       tea  collaborating with colleagues to develop inter...   \n",
       "1       tea  i'm committed to adapting teaching styles to a...   \n",
       "2       tea  my goal is to prepare students for success in ...   \n",
       "3       tea  i am dedicated to preparing students for succe...   \n",
       "4       tea  living life by default versus living life by d...   \n",
       "\n",
       "                                     processed_posts  \n",
       "0  collaborating with colleagues to develop inter...  \n",
       "1  i'm committed to adapting teaching styles to a...  \n",
       "2  my goal is to prepare students for success in ...  \n",
       "3  i am dedicated to preparing students for succe...  \n",
       "4  living life by default versus living life by d...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import in the saved model pkl\n",
    "model_sn = joblib.load(\"./pkl_files/model_sn.pkl\")\n",
    "model_tf = joblib.load(\"./pkl_files/model_tf.pkl\")\n",
    "model_jp = joblib.load(\"./pkl_files/model_jp.pkl\")\n",
    "tvec_sn = joblib.load(\"./pkl_files/tvec_SN.pkl\")\n",
    "tvec_tf = joblib.load(\"./pkl_files/tvec_TF.pkl\")\n",
    "tvec_jp = joblib.load(\"./pkl_files/tvec_JP.pkl\")\n",
    "\n",
    "# Read csv for test data\n",
    "df_linkedin = pd.read_csv(\"./cleaned_data/linkedin_cleaned.csv\")\n",
    "\n",
    "# See rows and columns; and details of first 5 rows\n",
    "df_linkedin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stemmer function which will tokenize and stem the corpus\n",
    "def stemmer(row):\n",
    "    '''Applies `PorterStemmer()` to each token in a document.\n",
    "    '''\n",
    "    # INstantiate stemmer\n",
    "    stem = PorterStemmer()\n",
    "\n",
    "    # Extracts post from each row\n",
    "    document = row[\"processed_posts\"]\n",
    "\n",
    "    # Tokenize sentence using RegexpTokenizer\n",
    "    re_tokenizer = RegexpTokenizer(pattern = r\"(?u)\\b(?:\\w\\w+|i|I)(?:[\\'\\'\\′\\ʼ](?:s|t|m|re|ve|d|ll))?\\b\")\n",
    "    list_of_tokens = re_tokenizer.tokenize(document)\n",
    "\n",
    "    # Applies stemmer to the list of tokens\n",
    "    stemmed_document = \"\"\n",
    "    for token in list_of_tokens:\n",
    "        stemmed_document += f\"{stem.stem(token)} \"\n",
    "    \n",
    "    return stemmed_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Generating Predictions/ MBTI Labels for LinkedIn Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Generating Vectorised Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X variable\n",
    "X = df_linkedin[[\"processed_posts\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20076\\2984788417.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"processed_posts\"] = X.apply(stemmer, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "# Stem our corpus\n",
    "X[\"processed_posts\"] = X.apply(stemmer, axis = 1)\n",
    "\n",
    "# Transform linkedin data on each of the tvec\n",
    "X_tvec_sn = pd.DataFrame(tvec_sn.transform(X[\"processed_posts\"]).todense(),\n",
    "                            columns = tvec_sn.get_feature_names_out())\n",
    "\n",
    "X_tvec_tf = pd.DataFrame(tvec_tf.transform(X[\"processed_posts\"]).todense(),\n",
    "                            columns = tvec_tf.get_feature_names_out())\n",
    "\n",
    "X_tvec_jp = pd.DataFrame(tvec_jp.transform(X[\"processed_posts\"]).todense(),\n",
    "                            columns = tvec_jp.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Generating Probability Predictions for Individual Traits Using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to determine probability predictions\n",
    "def generate_prob(model, X_tvec):\n",
    "    \n",
    "    # Obtain predictions\n",
    "    y_prediction = model.predict_proba(X_tvec)\n",
    "\n",
    "    # Extracting out one probability value to represent the trait\n",
    "    prob_list = [sublist[0] for sublist in y_prediction]\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the list of probabilities of each trait\n",
    "\n",
    "prob_sn = generate_prob(model_sn, X_tvec_sn)\n",
    "prob_tf = generate_prob(model_tf, X_tvec_tf)\n",
    "prob_jp = generate_prob(model_jp, X_tvec_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating database on LinkedIn job titles and their 3 traits\n",
    "job_titles = list(df_linkedin[\"job_title\"])\n",
    "linkedin_mbti = pd.DataFrame({\n",
    "    \"s_n\": prob_sn,\n",
    "    \"t_f\": prob_tf,\n",
    "    \"j_p\": prob_jp,\n",
    "})\n",
    "linkedin_mbti.set_index(pd.Series(job_titles, name = \"job_titles\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_n</th>\n",
       "      <th>t_f</th>\n",
       "      <th>j_p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_titles</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.341091</td>\n",
       "      <td>0.285007</td>\n",
       "      <td>0.498420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.256834</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.548492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.287066</td>\n",
       "      <td>0.289800</td>\n",
       "      <td>0.523861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.246035</td>\n",
       "      <td>0.218084</td>\n",
       "      <td>0.491402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.489610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.310018</td>\n",
       "      <td>0.227274</td>\n",
       "      <td>0.500285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.454863</td>\n",
       "      <td>0.379361</td>\n",
       "      <td>0.504664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.267909</td>\n",
       "      <td>0.234147</td>\n",
       "      <td>0.489678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.596118</td>\n",
       "      <td>0.484924</td>\n",
       "      <td>0.517964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.348030</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.503477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s_n       t_f       j_p\n",
       "job_titles                              \n",
       "tea         0.341091  0.285007  0.498420\n",
       "tea         0.256834  0.191431  0.548492\n",
       "tea         0.287066  0.289800  0.523861\n",
       "tea         0.246035  0.218084  0.491402\n",
       "tea         0.479142  0.414365  0.489610\n",
       "...              ...       ...       ...\n",
       "se          0.310018  0.227274  0.500285\n",
       "se          0.454863  0.379361  0.504664\n",
       "se          0.267909  0.234147  0.489678\n",
       "se          0.596118  0.484924  0.517964\n",
       "se          0.348030  0.261300  0.503477\n",
       "\n",
       "[240 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_mbti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Generating Recommender Systems: Profile-Based Recommendations\n",
    "\n",
    "(a) Generating MBTI from Job Seeker's Inputs\n",
    "- When a job seekers input their 'About' or LinkedIn posts, or write any text, their MBTI scores (probabilities for the 3 traits) will be generated.\n",
    "\n",
    "(b) Finding Job Titles/ Profiles with Similar MBTI as Job Seeker\n",
    "- With the MBTI score, the recommender system will look for the top 20 LinkedIn profiles/ job titles that has the closest MBTI score to the seeker. Euclidean distances between the seeker and each title's MBTI will be calculated, as a measure of similarity of MBTI scores between them. Each profile (with job title) will have their respective distance scores, ranked in ascending order.\n",
    "\n",
    "(c) Recommend Top 2 Job Titles\n",
    "- To determine the top 2 suitable job titles, the distance of each job title will be summed up, divided by the count of each job title to normalise the distances according to job titles. The lowest 2 distances and corresponding job titles will be recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Generating MBTI from Job Seeker's Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stemmer function which will tokenize and stem seeker text input\n",
    "def stemmer_seeker(document):\n",
    "    '''Applies `PorterStemmer()` to each token in a document.\n",
    "    '''\n",
    "    # Instantiate stemmer\n",
    "    stem = PorterStemmer()\n",
    "\n",
    "    # Tokenize sentence using RegexpTokenizer\n",
    "    re_tokenizer = RegexpTokenizer(pattern = r\"(?u)\\b(?:\\w\\w+|i|I)(?:[\\'\\'\\′\\ʼ](?:s|t|m|re|ve|d|ll))?\\b\")\n",
    "    list_of_tokens = re_tokenizer.tokenize(document)\n",
    "\n",
    "    # Applies stemmer to the list of tokens\n",
    "    stemmed_document = \"\"\n",
    "    for token in list_of_tokens:\n",
    "        stemmed_document += f\"{stem.stem(token)} \"\n",
    "    \n",
    "    return stemmed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of input text by job seeker \n",
    "document = \"I'm deeply passionate about data and using data to deliver results and achieve desired outcomes. I believe data is at the heart of what we all do, no matter what you do. I have 9+ years of professional experience - in shaping data and product strategy, driving innovation, and leading cross-functional teams to develop cutting-edge data-driven products in the advertising technology and ecommerce domain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem and transform text input\n",
    "seeker_tvec_sn = pd.DataFrame(tvec_sn.transform([stemmer_seeker(document)]).todense(),\n",
    "                            columns = tvec_sn.get_feature_names_out())\n",
    "\n",
    "seeker_tvec_tf = pd.DataFrame(tvec_tf.transform([stemmer_seeker(document)]).todense(),\n",
    "                            columns = tvec_tf.get_feature_names_out())\n",
    "\n",
    "seeker_tvec_jp = pd.DataFrame(tvec_jp.transform([stemmer_seeker(document)]).todense(),\n",
    "                            columns = tvec_jp.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the seeker's mbti probability scores\n",
    "seeker_prob_sn = generate_prob(model_sn, seeker_tvec_sn)\n",
    "seeker_prob_tf = generate_prob(model_tf, seeker_tvec_tf)\n",
    "seeker_prob_jp = generate_prob(model_jp, seeker_tvec_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s_n    0.468883\n",
       "t_f    0.286113\n",
       "j_p    0.495216\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing seeker's MBTI score into a series\n",
    "trait_types = linkedin_mbti.columns\n",
    "seeker = pd.Series(data=np.zeros(len(trait_types)), index=trait_types)\n",
    "\n",
    "seeker[\"s_n\"] = float(seeker_prob_sn[0])\n",
    "seeker[\"t_f\"] = float(seeker_prob_tf[0])\n",
    "seeker[\"j_p\"] = float(seeker_prob_jp[0])\n",
    "seeker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Finding Job Titles/ Profiles with Similar MBTI as Job Seeker & (c) Recommend Top 2 Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to determine top 2 matching mbti job titles\n",
    "\n",
    "def rec_top2_jobs(seeker_mbti, linkedin_mbti_dataset = linkedin_mbti):\n",
    "    \n",
    "    # obtaining euclidean distance between job titles' mbti and seeker's mbti\n",
    "    recommendations = [np.linalg.norm(linkedin_mbti_dataset.values[i] - seeker_mbti.values) for i in range(len(linkedin_mbti_dataset.values))]\n",
    "\n",
    "    # putting scores in a dataframe\n",
    "    recommendations_df = pd.DataFrame({\n",
    "    \"job_titles\": linkedin_mbti_dataset.index,\n",
    "    \"scores\": recommendations,\n",
    "    })\n",
    "\n",
    "    # Obtain top 20 similar mbti linkedin users\n",
    "    linkedin_top20 = recommendations_df.sort_values(by = \"scores\", ascending = True).head(20).reset_index(drop = True)\n",
    "\n",
    "    # Summming up number of each linkedin title present in the top 20\n",
    "    linkedin_top20_count = pd.Series(linkedin_top20.groupby(\"job_titles\")[\"scores\"].count())\n",
    "\n",
    "    # Summming up distances for each linkedin title present in the top 20\n",
    "    linkedin_top20 = pd.Series(linkedin_top20.groupby(\"job_titles\")[\"scores\"].sum())\n",
    "\n",
    "    # Obtaining average distance of each job title\n",
    "    linkedin_top20_aggregate = linkedin_top20 / linkedin_top20_count\n",
    "\n",
    "    # Extracting out top 2 'lowest'scoring job titles\n",
    "    top2_job_titles = list(linkedin_top20_aggregate.sort_values(ascending = True).index[0:2])\n",
    "\n",
    "    return top2_job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp', 'acc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matching seeker's mbti to determine top 2 job titles\n",
    "rec_top2_jobs(seeker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doodlesacer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
